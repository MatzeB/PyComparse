#!/usr/bin/env python3
"""Generate compact Unicode name lookup tables.

Run with:
  uv run scripts/gen_unicode_name_table.py

The generated table intentionally excludes algorithmic names for:
- HANGUL SYLLABLE ...
- CJK UNIFIED IDEOGRAPH-...

Those are handled by code in unicode_name_lookup.c.
"""

from __future__ import annotations

import unicodedata
from pathlib import Path

BLOCK_SIZE = 16
CODEPOINT_BITS = 20
MAX_CP = 0x110000
ALGO_HANGUL_PREFIX = "HANGUL SYLLABLE "
ALGO_CJK_PREFIX = "CJK UNIFIED IDEOGRAPH-"

OUT_H = Path("include/pycomparse/unicode_name_table.h")
OUT_C = Path("src/unicode_name_table.c")


def common_prefix_len(a: str, b: str) -> int:
    i = 0
    n = min(len(a), len(b))
    while i < n and a[i] == b[i]:
        i += 1
    return i


def collect_entries() -> list[tuple[str, int]]:
    entries: list[tuple[str, int]] = []
    for cp in range(MAX_CP):
        try:
            name = unicodedata.name(chr(cp))
        except ValueError:
            continue
        if name.startswith(ALGO_HANGUL_PREFIX) or name.startswith(ALGO_CJK_PREFIX):
            continue
        entries.append((name, cp))
    entries.sort(key=lambda it: it[0])
    return entries


def emit_u8_array(
    f, ctype: str, name: str, values: list[int], per_line: int = 16
) -> None:
    f.write(f"const {ctype} {name}[{len(values)}] = {{\n")
    for i in range(0, len(values), per_line):
        chunk = values[i : i + per_line]
        f.write("  " + ", ".join(str(v) for v in chunk) + ",\n")
    f.write("};\n\n")


def emit_u32_array(
    f, ctype: str, name: str, values: list[int], per_line: int = 8
) -> None:
    f.write(f"const {ctype} {name}[{len(values)}] = {{\n")
    for i in range(0, len(values), per_line):
        chunk = values[i : i + per_line]
        f.write("  " + ", ".join(str(v) for v in chunk) + ",\n")
    f.write("};\n\n")


def pack_fixed_bits(values: list[int], bits: int) -> bytearray:
    out = bytearray()
    bitbuf = 0
    bitcount = 0
    for value in values:
        assert 0 <= value < (1 << bits)
        bitbuf |= value << bitcount
        bitcount += bits
        while bitcount >= 8:
            out.append(bitbuf & 0xFF)
            bitbuf >>= 8
            bitcount -= 8
    if bitcount > 0:
        out.append(bitbuf & 0xFF)
    return out


def generate() -> None:
    entries = collect_entries()
    entry_count = len(entries)
    block_count = (entry_count + BLOCK_SIZE - 1) // BLOCK_SIZE

    max_name_len = max(len(name) for name, _ in entries)
    assert max_name_len <= 255

    codepoints = [cp for _, cp in entries]
    packed_codepoints = pack_fixed_bits(codepoints, CODEPOINT_BITS)

    first_offsets: list[int] = []
    first_blob = bytearray()

    block_data_offsets: list[int] = []
    block_data = bytearray()

    for block in range(block_count):
        start = block * BLOCK_SIZE
        end = min(start + BLOCK_SIZE, entry_count)
        block_entries = entries[start:end]

        first_name = block_entries[0][0]
        first_offsets.append(len(first_blob))
        first_blob.extend(first_name.encode("ascii"))
        first_blob.append(0)

        block_data_offsets.append(len(block_data))

        prev = first_name
        for name, _ in block_entries[1:]:
            prefix = common_prefix_len(prev, name)
            suffix = name[prefix:]
            assert 0 <= prefix <= 255
            assert 0 <= len(suffix) <= 255
            block_data.append(prefix)
            block_data.append(len(suffix))
            block_data.extend(suffix.encode("ascii"))
            prev = name

    block_data_offsets.append(len(block_data))
    packed_codepoint_bytes = len(packed_codepoints)
    first_blob_bytes = len(first_blob)
    block_data_bytes = len(block_data)
    block_data_offset_count = block_count + 1

    with OUT_H.open("w", encoding="ascii") as f:
        f.write(
            f"""\
/* Generated by scripts/gen_unicode_name_table.py - do not edit. */

#pragma once

#include <stdint.h>

#ifdef __cplusplus
extern "C" {{
#endif

#define UNICODE_NAME_BLOCK_SIZE {BLOCK_SIZE}
#define UNICODE_NAME_CODEPOINT_BITS {CODEPOINT_BITS}
#define UNICODE_NAME_CODEPOINT_MASK ((1u << {CODEPOINT_BITS}) - 1u)
#define UNICODE_NAME_ENTRY_COUNT {entry_count}
#define UNICODE_NAME_BLOCK_COUNT {block_count}
#define UNICODE_NAME_MAX_LENGTH {max_name_len}
#define UNICODE_NAME_CODEPOINT_BYTES {packed_codepoint_bytes}

extern const uint8_t unicode_name_codepoints[{packed_codepoint_bytes}];
extern const uint32_t unicode_name_block_first_offsets[{block_count}];
extern const uint8_t unicode_name_block_first_names[{first_blob_bytes}];
extern const uint32_t unicode_name_block_data_offsets[{block_data_offset_count}];
extern const uint8_t unicode_name_block_data[{block_data_bytes}];

#ifdef __cplusplus
}}
#endif
"""
        )

    with OUT_C.open("w", encoding="ascii") as f:
        f.write(
            """\
/* Generated by scripts/gen_unicode_name_table.py - do not edit. */

#include "pycomparse/unicode_name_table.h"

"""
        )

        emit_u8_array(
            f,
            "uint8_t",
            "unicode_name_codepoints",
            list(packed_codepoints),
        )
        emit_u32_array(
            f,
            "uint32_t",
            "unicode_name_block_first_offsets",
            first_offsets,
        )
        emit_u8_array(
            f,
            "uint8_t",
            "unicode_name_block_first_names",
            list(first_blob),
        )
        emit_u32_array(
            f,
            "uint32_t",
            "unicode_name_block_data_offsets",
            block_data_offsets,
        )
        emit_u8_array(
            f,
            "uint8_t",
            "unicode_name_block_data",
            list(block_data),
        )

    total_size = (
        packed_codepoint_bytes
        + len(first_offsets) * 4
        + first_blob_bytes
        + len(block_data_offsets) * 4
        + block_data_bytes
    )
    print(f"entries={entry_count} blocks={block_count} max_name_len={max_name_len}")
    print(
        f"sizes: codepoints={packed_codepoint_bytes} "
        f"first_offsets={len(first_offsets) * 4} "
        f"first_blob={first_blob_bytes} "
        f"block_data_offsets={len(block_data_offsets) * 4} "
        f"block_data={block_data_bytes} "
        f"total={total_size} bytes"
    )


if __name__ == "__main__":
    generate()
